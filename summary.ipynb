{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77880fa9-9e1d-4d3c-88da-ad596a61dd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to 'LDA_Evaluation_Results_Homo.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import StratifiedKFold, LeaveOneOut\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from matplotlib.patches import Ellipse\n",
    "from scipy.stats import chi2\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "\n",
    "# Function to evaluate models and save results\n",
    "def evaluate_models(directory_path):\n",
    "    csv_files = [f for f in os.listdir(directory_path) if f.endswith('.csv')]\n",
    "    results = []\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        file_path = os.path.join(directory_path, csv_file)\n",
    "        polymers = pd.read_csv(file_path)\n",
    "        polymers_data = polymers[polymers[\"test\"] == 1]\n",
    "        y = polymers_data[\"sample\"]\n",
    "        x = polymers_data.drop([\"test\", \"sample\"], axis=1)\n",
    "\n",
    "        # Determine the maximum number of components for LDA\n",
    "        n_classes = len(y.unique())\n",
    "        n_features = x.shape[1]\n",
    "        max_components = min(n_classes - 1, n_features)\n",
    "\n",
    "        # Perform Stratified K-Fold Cross-Validation\n",
    "        stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "        test_scores = []\n",
    "\n",
    "        for train_index, test_index in stratified_kfold.split(x, y):\n",
    "            X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            \n",
    "            lda = LinearDiscriminantAnalysis(n_components=max_components).fit(X_train, y_train)\n",
    "            score = lda.score(X_test, y_test)\n",
    "            test_scores.append(score)\n",
    "\n",
    "        overall_accuracy = np.mean(test_scores)\n",
    "        \n",
    "        # Perform Leave-One-Out Cross-Validation (Jackknife)\n",
    "        loo = LeaveOneOut()\n",
    "        loo_scores = []\n",
    "\n",
    "        for train_index, test_index in loo.split(x):\n",
    "            X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            \n",
    "            lda = LinearDiscriminantAnalysis(n_components=max_components).fit(X_train, y_train)\n",
    "            score = lda.score(X_test, y_test)\n",
    "            loo_scores.append(score)\n",
    "\n",
    "        average_score = np.mean(loo_scores)\n",
    "        \n",
    "        # Calculate centroids for each class\n",
    "        x_scores = lda.transform(x)\n",
    "        x_scores_df = pd.DataFrame(x_scores, columns=[f'Component {i+1}' for i in range(x_scores.shape[1])])\n",
    "        x_scores_df['sample'] = y.values\n",
    "        centroids = x_scores_df.groupby('sample').mean()\n",
    "\n",
    "        # Calculate Euclidean distances between centroids\n",
    "        centroid_distances = pdist(centroids.values, metric='euclidean')\n",
    "        mean_centroid_distance = np.mean(centroid_distances)\n",
    "        max_centroid_distance = np.max(centroid_distances)\n",
    "        min_centroid_distance = np.min(centroid_distances)\n",
    "        \n",
    "        # Find the classes corresponding to the minimum and maximum distances\n",
    "        distance_matrix = squareform(centroid_distances)\n",
    "        min_dist_indices = np.unravel_index(np.argmin(distance_matrix + np.eye(len(centroids)) * np.max(distance_matrix)), distance_matrix.shape)\n",
    "        max_dist_indices = np.unravel_index(np.argmax(distance_matrix), distance_matrix.shape)\n",
    "        \n",
    "        min_distance_classes = (centroids.index[min_dist_indices[0]], centroids.index[min_dist_indices[1]])\n",
    "        max_distance_classes = (centroids.index[max_dist_indices[0]], centroids.index[max_dist_indices[1]])\n",
    "\n",
    "        # Compute variance statistics\n",
    "        variances = lda.explained_variance_ratio_\n",
    "        max_variance = np.max(variances)\n",
    "        min_variance = np.min(variances)\n",
    "        avg_variance = np.mean(variances)\n",
    "\n",
    "        # Compute the variance of centroids\n",
    "        centroid_variance = np.var(centroids.values, axis=0)\n",
    "        total_centroid_variance = np.mean(centroid_variance)\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            'File': csv_file,\n",
    "            'Stratified K-Fold Accuracy': overall_accuracy * 100,\n",
    "            'LOO CV Accuracy': average_score * 100,\n",
    "            'Mean Centroid Distance': mean_centroid_distance,\n",
    "        })\n",
    "        \n",
    "        # Save heatmap for the Euclidean distances with scale bar from 0 to 100\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        # Optional: Visualize the distance matrix as a heatmap with custom colormap\n",
    "        cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_cmap\", [\"#80BE81\", \"#FBEA92\", \"#D96E6C\"])\n",
    "\n",
    "        sns.heatmap(squareform(centroid_distances), cmap=cmap, xticklabels=centroids.index, yticklabels=centroids.index, vmin=0, vmax=200)\n",
    "        #plt.title(f\"Heatmap of Euclidean Distances_n_component=2_sample: {csv_file}\")\n",
    "        #plt.savefig(f\"Heatmap_Euclidean_Distances_{csv_file}_n_component=2.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # Save results to a CSV file\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(\"all_first.csv\", index=False)\n",
    "    print(\"\\nResults saved to 'LDA_Evaluation_Results_Homo.csv'.\")\n",
    "\n",
    "# Run evaluation on the directory\n",
    "directory_path = \"data/all_first\"  # Specify your directory path here\n",
    "evaluate_models(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28012929-d8d1-4774-a813-b754425ad183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2D polt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import LeaveOneOut, StratifiedKFold\n",
    "from matplotlib.patches import Ellipse\n",
    "from scipy.stats import chi2\n",
    "\n",
    "\n",
    "A=\"data/AB_fromPCA/LDA_AB_4sensors_Normalized_fromPCA(2)_9.csv\"\n",
    "def plot_lda_with_ellipse(scale_bool):\n",
    "    polymers = pd.read_csv(A) #440/470, 440/510\n",
    "    polymers_train = polymers[polymers[\"test\"]==1]\n",
    "    y_train_dummies = polymers_train[\"sample\"]\n",
    "    x_train = polymers_train.drop([\"test\", \"sample\"], axis=1)\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "    x_scores = lda.fit(x_train, y_train_dummies).transform(x_train)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "    cmap = {'AX-B120':\"magenta\", 'AX-B121': \"#009193\", 'AX-B135':\"peru\", 'AX-B136':\"green\", 'AX-B137':\"orange\", 'AX-B138':\"blue\", 'AX-B140':\"tomato\", 'AX-B141':\"purple\", 'AX-B139':\"darkblue\", \n",
    "             'AX-B164': \"#44840C\", 'AX-B166': \"#945200\", 'AX-B167': \"#0096FF\", 'AX-B168': \"#716DF6\", 'AX-B169': \"#FADFB6\", 'AX-B170': \"#F5B455\"\n",
    "           , 'AX-B171': \"#F4A636\", 'AX-B194': \"#F8CA87\", 'AX-B195': \"#DC0D23\", 'AX-B196': \"#83800F\"}\n",
    "\n",
    "    # 目盛の調整\n",
    "    plt.rcParams['axes.linewidth'] = 2\n",
    "    ax.tick_params(width=2)\n",
    "    ax.tick_params(axis='both', which='both', direction='in', length=6)\n",
    "    \n",
    "    ax.set_xlim(-80, 60)\n",
    "    #ax.set_xticks([-70, -60, -50, -40, -30, -20, -10, 0, 10, 20, 30, 40, 50, 60])\n",
    "    ax.set_ylim(-20, 25)\n",
    "    #ax.set_yticks([-35, -30, -25, -20, -15, -10, -5, 0, 5, 10, 15, 20, 25])  \n",
    "\n",
    "    ax.set_xlabel('Score(1)')\n",
    "    ax.set_ylabel('Score(2)')\n",
    "    ax.set_title('LDA Score Plot')\n",
    "    \n",
    "    \n",
    "\n",
    "    for i, (t1, t2) in enumerate(x_scores):\n",
    "        color = cmap[polymers_train[\"sample\"].iloc[i]]\n",
    "        plt.scatter(t1, t2, c='None', edgecolors=color, marker=\"o\", label='None', linewidth=1,  s=50)\n",
    "\n",
    "        if scale_bool:\n",
    "            class_data = x_scores[y_train_dummies == y_train_dummies.iloc[i]]\n",
    "            class_covariance = np.cov(class_data.T)\n",
    "            n = class_data.shape[0]\n",
    "            pooled_covariance = class_covariance * (n - 1) / (n - 2)\n",
    "            mean = np.mean(class_data, axis=0)\n",
    "            eigenvalues, eigenvectors = np.linalg.eigh(pooled_covariance)\n",
    "            order = eigenvalues.argsort()[::-1]\n",
    "            eigenvalues, eigenvectors = eigenvalues[order], eigenvectors[:, order]\n",
    "            angle = np.degrees(np.arctan2(eigenvectors[1, 0], eigenvectors[0, 0]))\n",
    "            width, height = 2 * np.sqrt(eigenvalues * chi2.ppf(0.95, 2))\n",
    "            ell = Ellipse(xy=(mean[0], mean[1]), width=width, height=height, angle=angle,\n",
    "                          edgecolor=color, linestyle='-', linewidth=2, fill=False)\n",
    "            ax.add_patch(ell)\n",
    "            \n",
    "    #plt.savefig(\"LDA_4sensors_ratio-All-H5A(-).png\", dpi=600)\n",
    "    plt#show()\n",
    "    \n",
    "    explained_variance_ratio = lda.explained_variance_ratio_\n",
    "    np.set_printoptions(precision=4)\n",
    "    print(\"Explained Variance Ratio (LDA):\", explained_variance_ratio)\n",
    "\n",
    "\n",
    "def lda_loocv():\n",
    "    polymers = pd.read_csv(A) #440/470, 440/510\n",
    "    polymers_data = polymers[polymers[\"test\"] == 1]\n",
    "    y = polymers_data[\"sample\"]\n",
    "    x = polymers_data.drop(([\"test\", \"sample\"]), axis=1)\n",
    "\n",
    "    loo = LeaveOneOut()\n",
    "\n",
    "    misclassified = []\n",
    "    actual_classes = []\n",
    "    predicted_classes = []\n",
    "\n",
    "    for train_index, test_index in loo.split(x):\n",
    "        X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        lda = LinearDiscriminantAnalysis(n_components=2).fit(X_train, y_train)\n",
    "        prediction = lda.predict(X_test)\n",
    "\n",
    "        if prediction != y_test.values[0]:\n",
    "            misclassified.append((y_test.values[0], prediction[0]))\n",
    "\n",
    "        actual_classes.append(y_test.values[0])\n",
    "        predicted_classes.append(prediction[0])\n",
    "\n",
    "    for actual, predicted in misclassified:\n",
    "        print(f\"Actual Class: {actual}, Predicted Class: {predicted}\")\n",
    "\n",
    "    accuracy = np.mean(np.array(actual_classes) == np.array(predicted_classes))\n",
    "    print('Leave-One-Out Cross-Validation Accuracy (LOOCV): {:.2f}%'.format(accuracy * 100))\n",
    "\n",
    "\n",
    "def lda_kfold():\n",
    "    polymers = pd.read_csv(A) #440/470, 440/510\n",
    "    polymers_data = polymers[polymers[\"test\"] == 1]\n",
    "    y = polymers_data[\"sample\"]\n",
    "    x = polymers_data.drop(([\"test\", \"sample\"]), axis=1)\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "    test_scores = []\n",
    "\n",
    "    for train_index, test_index in stratified_kfold.split(x, y):\n",
    "        X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        lda = LinearDiscriminantAnalysis(n_components=2).fit(X_train, y_train)\n",
    "        score = lda.score(X_test, y_test)\n",
    "        test_scores.append(score)\n",
    "        print('Test set score: {}'.format(score))\n",
    "\n",
    "    overall_accuracy = np.mean(test_scores)\n",
    "    print('Overall Test Set Accuracy: {:.2f}%'.format(overall_accuracy * 100))\n",
    "\n",
    "\n",
    "def main():\n",
    "    lda_loocv()\n",
    "    lda_kfold()\n",
    "    plot_lda_with_ellipse(scale_bool=1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb1cf85-3491-453d-b637-e657dc3e2132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3d polt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from itertools import combinations\n",
    "\n",
    "A = \"data/ab_fromPCA/LDA_AB_4sensors_Normalized_fromPCA(2).csv\"\n",
    "\n",
    "def plot_lda_with_ellipse_3d(component1=1, component2=2, component3=3, x_range=None, y_range=None, z_range=None):\n",
    "    polymers = pd.read_csv(A)\n",
    "    polymers_train = polymers[polymers[\"test\"] == 1]\n",
    "    y_train_dummies = polymers_train[\"sample\"]\n",
    "    x_train = polymers_train.drop([\"test\", \"sample\"], axis=1)\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis(n_components=3)\n",
    "    x_scores = lda.fit(x_train, y_train_dummies).transform(x_train)\n",
    "\n",
    "    explained_variance_ratio = lda.explained_variance_ratio_\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    cmap = {'AX-B120': \"magenta\", 'AX-B135': \"peru\", 'AX-B136': \"green\", 'AX-B137': \"orange\", 'AX-B138': \"blue\", \n",
    "            'AX-B140': \"tomato\", 'AX-B141': \"purple\", 'AX-B139': \"darkblue\", 'AX-B121': \"#009193\", \n",
    "            'AX-B164': \"#44840C\", 'AX-B166': \"#945200\", 'AX-B167': \"#0096FF\", 'AX-B168': \"#716DF6\", \n",
    "            'AX-B169': \"#FADFB6\", 'AX-B170': \"#F5B455\", 'AX-B171': \"#F4A636\", 'AX-B194': \"#F8CA87\", \n",
    "            'AX-B195': \"#DC0D23\", 'AX-B196': \"#83800F\"}\n",
    "\n",
    "    selected_scores = x_scores[:, [component1-1, component2-1, component3-1]]\n",
    "\n",
    "    for sample in polymers_train[\"sample\"].unique():\n",
    "        mask = polymers_train[\"sample\"] == sample\n",
    "        points = selected_scores[mask]\n",
    "\n",
    "        # プロット同士をすべてペアにして線を描く\n",
    "        for p1, p2 in combinations(points, 2):\n",
    "            fig.add_trace(go.Scatter3d(\n",
    "                x=[p1[0], p2[0]],\n",
    "                y=[p1[1], p2[1]],\n",
    "                z=[p1[2], p2[2]],\n",
    "                mode='lines',\n",
    "                line=dict(color=cmap[sample], width=1),\n",
    "                showlegend=False  # すべての線に対して凡例を表示しない\n",
    "            ))\n",
    "\n",
    "        # 各クラスの点を表示\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=points[:, 0],\n",
    "            y=points[:, 1],\n",
    "            z=points[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(size=1, color=cmap[sample]),\n",
    "            name=sample\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis=dict(title=f'LDA Component {component1} ({explained_variance_ratio[component1-1]*100:.2f}%)',\n",
    "                       range=x_range),  # x軸の範囲を設定\n",
    "            yaxis=dict(title=f'LDA Component {component2} ({explained_variance_ratio[component2-1]*100:.2f}%)',\n",
    "                       range=y_range),  # y軸の範囲を設定\n",
    "            zaxis=dict(title=f'LDA Component {component3} ({explained_variance_ratio[component3-1]*100:.2f}%)',\n",
    "                       range=z_range),  # z軸の範囲を設定\n",
    "            aspectmode='cube'  # 正方形の軸を指定\n",
    "        ),\n",
    "        title=f'LDA 3D Plot: Components {component1}, {component2}, {component3}',\n",
    "        width=1200,  # グラフの幅\n",
    "        height=800   # グラフの高さ\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    np.set_printoptions(precision=4)\n",
    "    print(\"Explained Variance Ratio (LDA):\", explained_variance_ratio)\n",
    "\n",
    "# 軸範囲を指定する例\n",
    "plot_lda_with_ellipse_3d(component1=1, component2=2, component3=3, x_range=[-60, 60], y_range=[-40, 20], z_range=[-40, 30])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
